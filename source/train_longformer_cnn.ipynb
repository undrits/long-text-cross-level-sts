{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_longformer_cnn.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMXqLOGAuDp8Jem1aG6w5Au"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-28TIzH2yImV"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ejsZNCV8kWIu"},"source":["!pip install transformers jsonlines datasets pyarrow  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PINaP7eOR61P"},"source":["# install nvidia apex to use mixed precision\n","\n","try:\n","  import apex\n","except:\n","  !git clone https://github.com/NVIDIA/apex\n","  %cd apex\n","  !pip install -v --no-cache-dir ./"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NHOAYvIGScpU"},"source":["# Load Data as HF dataset\n"]},{"cell_type":"code","metadata":{"id":"u1rDeq50mDbk"},"source":["# mount drive to access data\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gsbTQLiPmGgw","executionInfo":{"status":"ok","timestamp":1621912210259,"user_tz":240,"elapsed":1402,"user":{"displayName":"Yulia Spektor","photoUrl":"https://lh6.googleusercontent.com/-U5iEGwAoTOc/AAAAAAAAAAI/AAAAAAABWY4/2QdsKenvlRg/s64/photo.jpg","userId":"11042471546002015818"}}},"source":["# load data\n","\n","import datasets\n","\n","DIR = \"/content/gdrive/MyDrive/CUNY_Comp_Ling/advanced_nlp/term_project/data/\"\n","TRAIN = 'train.jsonl'\n","DEV = 'dev.jsonl'\n","TEST = 'test.jsonl'\n","\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"D2uEbjEqJknE"},"source":["dataset = datasets.load_dataset('json', data_files={'train': DIR + TRAIN, 'validation': DIR + DEV, 'test': DIR + TEST})  \n","\n","print(dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRpPXFL6c7Fo"},"source":["# check the label distribution\n","\n","targets = []\n","for data in dataset.values():\n","  for d in data:\n","    if d['label'] not in targets:\n","      targets.append(d['label'])\n","\n","    \n","sorted(targets)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Z_RdBcLSlUa"},"source":["# Tokenize"]},{"cell_type":"code","metadata":{"id":"FFB7kbqMkrNN","executionInfo":{"status":"ok","timestamp":1621912267889,"user_tz":240,"elapsed":3152,"user":{"displayName":"Yulia Spektor","photoUrl":"https://lh6.googleusercontent.com/-U5iEGwAoTOc/AAAAAAAAAAI/AAAAAAABWY4/2QdsKenvlRg/s64/photo.jpg","userId":"11042471546002015818"}}},"source":["from transformers import LongformerTokenizer\n","# LongformerTokenizer is identical to RobertaTokenizer (SentencePiece)\n","tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"X9S8s0D9k4U4","executionInfo":{"status":"ok","timestamp":1621912269269,"user_tz":240,"elapsed":193,"user":{"displayName":"Yulia Spektor","photoUrl":"https://lh6.googleusercontent.com/-U5iEGwAoTOc/AAAAAAAAAAI/AAAAAAABWY4/2QdsKenvlRg/s64/photo.jpg","userId":"11042471546002015818"}}},"source":["import torch\n","import datasets\n","from typing import List, Dict\n","\n","def prep_data(data):\n","    encodings = tokenizer.encode_plus(\n","        data['abstract'], \n","        data['text'],\n","        pad_to_max_length=True, \n","        max_length=4096,\n","        add_special_tokens=True,\n","        return_token_type_ids=False,\n","        return_attention_mask=True,\n","        padding='max_length', \n","        truncation=True,\n","        )\n","    # add the 1st CLS as a global token\n","    global_attention_mask = torch.zeros(len(encodings.input_ids), dtype=torch.long)\n","    global_attention_mask[0] = 1\n","    encodings.update({'global_attention_mask': global_attention_mask})\n","\n","    # convert label to float tensor for regression training\n","    label = data['label']\n","    targets = torch.tensor(label, dtype=torch.float)\n","    targets.contiguous()\n","    # to match the shape of the input tensor (1,1)\n","    targets = targets.view(-1, 1)\n","    encodings.update({'labels': targets})\n","\n","    return encodings"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"ONyV9uRxKysp"},"source":["# convert data\n","\n","train_set = dataset['train']\n","validation_set = dataset['validation']\n","test_set = dataset['test']\n","\n","train_set =  train_set.map(prep_data)\n","validation_set =  validation_set.map(prep_data)\n","test_set = test_set.map(prep_data)\n","\n","columns = ['input_ids', 'attention_mask', 'global_attention_mask', 'labels']\n","train_set.set_format(type='torch', columns=columns)\n","validation_set.set_format(type='torch', columns=columns)\n","test_set.set_format(type='torch', columns=columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2QiCMXoBZSV"},"source":["train_set.shape, validation_set.shape, test_set.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y68sWrmkA1Yk"},"source":["print(train_set[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b6NwvXOtSvuy"},"source":["# Create Dataloader"]},{"cell_type":"code","metadata":{"id":"68n5nUlGLFfj","executionInfo":{"status":"ok","timestamp":1621912360430,"user_tz":240,"elapsed":181,"user":{"displayName":"Yulia Spektor","photoUrl":"https://lh6.googleusercontent.com/-U5iEGwAoTOc/AAAAAAAAAAI/AAAAAAABWY4/2QdsKenvlRg/s64/photo.jpg","userId":"11042471546002015818"}}},"source":["from torch.utils.data import DataLoader\n","\n","batch_size = 1 # batch size of 1 with gradient accumulation to 32\n","\n","train_loader = DataLoader(train_set, batch_size, shuffle=True, num_workers=2)\n","valid_loader = DataLoader(validation_set, batch_size, shuffle=True, num_workers=2)\n","test_loader = DataLoader(test_set, batch_size, shuffle=True, num_workers=2)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZQiXKXaGwEkd"},"source":["# Train\n"]},{"cell_type":"code","metadata":{"id":"EA9V8DD4wGJq","executionInfo":{"status":"ok","timestamp":1621912228176,"user_tz":240,"elapsed":4241,"user":{"displayName":"Yulia Spektor","photoUrl":"https://lh6.googleusercontent.com/-U5iEGwAoTOc/AAAAAAAAAAI/AAAAAAABWY4/2QdsKenvlRg/s64/photo.jpg","userId":"11042471546002015818"}}},"source":["import apex\n","import datasets\n","import numpy as np\n","import os\n","import pandas as pd\n","from pathlib import Path\n","import random\n","import tqdm\n","from typing import List, Dict, Optional, Union, Tuple\n","\n","import torch\n","from torch import nn\n","from torch import functional as F\n","from torch.utils.data import (\n","    TensorDataset,\n","    random_split,\n","    RandomSampler,\n","    DataLoader,\n",")\n","\n","from transformers import (\n","    LongformerForSequenceClassification,\n","    LongformerModel,\n","    LongformerConfig, \n","    Trainer, \n","    TrainingArguments,\n","    AdamW,\n",")\n","\n","from transformers.file_utils import ModelOutput"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"BG6e_-RJX59I","executionInfo":{"status":"ok","timestamp":1621912229616,"user_tz":240,"elapsed":180,"user":{"displayName":"Yulia Spektor","photoUrl":"https://lh6.googleusercontent.com/-U5iEGwAoTOc/AAAAAAAAAAI/AAAAAAABWY4/2QdsKenvlRg/s64/photo.jpg","userId":"11042471546002015818"}}},"source":["# Copied from transformers.models.longformer.modeling_longformer.LongformerSequenceClassifierOutput\n","\n","class LongformerSequenceClassifierOutput(ModelOutput):\n","\n","    loss: Optional[torch.FloatTensor] = None\n","    logits: torch.FloatTensor = None\n","    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n","    attentions: Optional[Tuple[torch.FloatTensor]] = None\n","    global_attentions: Optional[Tuple[torch.FloatTensor]] = None"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"bD5fWjnIAFsq","executionInfo":{"status":"ok","timestamp":1621912231242,"user_tz":240,"elapsed":169,"user":{"displayName":"Yulia Spektor","photoUrl":"https://lh6.googleusercontent.com/-U5iEGwAoTOc/AAAAAAAAAAI/AAAAAAABWY4/2QdsKenvlRg/s64/photo.jpg","userId":"11042471546002015818"}}},"source":["class LongformerCNN(LongformerModel):\n","    def __init__(self, config,\n","                 channels=(4096,4096),\n","                 filter_sizes=(3,3),\n","                 num_filters=(100,100), \n","                 dropout=0.1,\n","                 num_labels=1,\n","                 ):\n","        super().__init__(config)\n","        self.num_labels=num_labels\n","\n","        # embedding model\n","        self.longformer = LongformerModel.from_pretrained(\n","            'allenai/longformer-base-4096',\n","            add_pooling_layer=False,\n","            )\n","        \n","        # cnn\n","        self.filter_sizes=filter_sizes\n","        self.num_filters=num_filters\n","        self.convs = nn.ModuleList([\n","            nn.Conv1d(in_channels=channels[i],\n","                      out_channels=self.num_filters[i],\n","                      kernel_size=self.filter_sizes[i],\n","                      padding=1,\n","                      stride=1) # from He et al 2016 PWIM paper\n","            for i in range(len(filter_sizes))\n","        ])\n","\n","        # dense + sigmoid\n","        self.dense = nn.Linear(np.sum(self.num_filters), self.num_labels)\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self,  input_ids,\n","              attention_mask,\n","              global_attention_mask,\n","              labels,\n","              return_dict=True):\n","\n","        outputs = self.longformer(\n","            input_ids=input_ids, \n","            attention_mask=attention_mask,\n","            global_attention_mask=global_attention_mask\n","            )\n","        seq_output = outputs[0]\n","        conv_output = [nn.functional.relu(conv(seq_output)) for conv in self.convs]\n","        pooled_output = [nn.MaxPool1d(kernel_size=output.shape[2])(output)\n","            for output in conv_output]\n","        concat_output = torch.cat([pool.squeeze(dim=2) for pool in pooled_output], dim=1)\n","        logits = self.dense(self.dropout(concat_output))\n","        logits = self.sigmoid(logits)\n","        \n","        # from  transformers.models.longformer.modeling_longformer.LongformerForSequenceClassification\n","        loss = None\n","        if labels is not None:\n","            loss_fct = nn.MSELoss()\n","            if self.num_labels == 1:\n","                loss = loss_fct(logits.squeeze(), labels.squeeze())\n","            else:\n","                loss = loss_fct(logits, labels)\n","        \n","        if not return_dict:\n","            output = (logits,) + outputs[2:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return LongformerSequenceClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","            global_attentions=outputs.global_attentions,\n","        )"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBVXekxmyzrF","executionInfo":{"status":"ok","timestamp":1621901615025,"user_tz":240,"elapsed":181,"user":{"displayName":"Yulia Spektor","photoUrl":"https://lh6.googleusercontent.com/-U5iEGwAoTOc/AAAAAAAAAAI/AAAAAAABWY4/2QdsKenvlRg/s64/photo.jpg","userId":"11042471546002015818"}}},"source":["# define the training arguments\n","\n","SAVE_PATH = DIR + 'longformer_cnn_4096/'\n","\n","training_args = TrainingArguments(\n","    output_dir = SAVE_PATH,\n","    do_train = True,\n","    do_eval = True,\n","    num_train_epochs = 1,\n","    per_device_train_batch_size = 1, # as in the paper\n","    gradient_accumulation_steps = 32, # as in the paper    \n","    per_device_eval_batch_size= 8,\n","    evaluation_strategy = \"steps\",\n","    eval_steps = 100,\n","    disable_tqdm = False, \n","    load_best_model_at_end=True,\n","    learning_rate = 3e-5, # from paper (default = 5e-5)\n","    warmup_steps=len(train_set)//10,\n","    weight_decay=0.01,\n","    logging_steps = 500, # =default\n","    fp16 = True,\n","    fp16_opt_level = 'O1', # default for apex mixed precision\n","    logging_dir= DIR + '/logs/',\n","    dataloader_num_workers = 2,\n","    run_name = 'longformer-cnn',\n",")"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"zzJ9X4Dd0Bp8"},"source":["# instantiate model\n","\n","config = LongformerConfig(\n","    num_labels=1, # regression\n","    gradient_checkpointing=True,\n","    vocab_size=tokenizer.vocab_size)\n","lf = LongformerCNN(config)\n","lf.config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T2T2A_ph3ojT"},"source":["# resize token embeddings\n","lf.resize_token_embeddings(len(tokenizer))\n","\n","# train\n","trainer = Trainer(\n","    model = lf,\n","    args = training_args,\n","    train_dataset = train_set,\n","    eval_dataset = validation_set,\n",")\n","\n","# set device to cuda\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","trainer.train()\n","\n","# save best model\n","lf.save_pretrained(SAVE_PATH)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dqDE7iUVqQPz"},"source":["import pprint\n","try:\n","  eval_metrics = trainer.evaluate()\n","  pprint.pprint(eval_metrics)\n","except:\n","  print(\"no eval\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-TeBZH23VV6j"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"KDn8VqQyd1KK"},"source":["# save predictions\n","\n","import numpy as np\n","import pandas as pd\n","import copy\n","import gc\n","\n","SAVE_PATH = DIR + 'longformer_cnn_4096/'\n","lf = LongformerCNN.from_pretrained(SAVE_PATH)\n","\n","PREDS_SAVE_PATH = DIR + \"longformer_cnn_predictions.csv\"\n","\n","df = pd.DataFrame(columns=['predictions', 'gold_labels'])\n","df.to_csv(PREDS_SAVE_PATH)\n","\n","lf.to('cuda')\n","\n","for batch in test_loader:\n","    input_ids = batch[\"input_ids\"].to('cuda')\n","    attention_mask = batch[\"attention_mask\"].to('cuda')\n","    global_attention_mask = batch['global_attention_mask'].to('cuda')\n","    \n","    outputs = lf(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                global_attention_mask=global_attention_mask,\n","                labels=None,\n","            )\n","\n","    labels = batch['labels']\n","    logits = outputs['logits']\n","    preds = logits.cpu().data.numpy()\n","    targets = copy.deepcopy(labels[0].numpy())\n","    predictions = copy.deepcopy(preds)\n","    results = {\n","        'predictions': predictions[0][0],\n","        'gold_labels': targets[0][0],\n","        }\n","    df = pd.DataFrame(columns=['predictions', 'gold_labels'])\n","    df = df.append(results, ignore_index=True)\n","    df.to_csv(PREDS_SAVE_PATH, mode='a', header=False)\n","\n","    # clear CUDA memory\n","    del input_ids\n","    del attention_mask\n","    del global_attention_mask\n","    del logits\n","    del outputs\n","    gc.collect()"],"execution_count":null,"outputs":[]}]}